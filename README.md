# Fine-Tuning and Inference Using GPT-2 and GPT-4 Models


**Model 1: GPT-2**
I initially started with fine-tuning GPT-2, attempting to get specific outputs that align with my project requirements. However, the results have been inconsistent or not as accurate as needed.

**Model 2: GPT-4**
After running into limitations with GPT-2, I transitioned to using GPT-4. The approach has involved providing correct prompts to obtain better responses and results. The switch to GPT-4 has significantly improved the quality of the outputs.

**Project Goals**
*    Fine-tune GPT-2 for specific tasks.
*    Evaluate GPT-2's performance against GPT-4.
*    Enhance the output quality using advanced techniques with GPT-4 and specific prompts.


**Technology Stack**
-    Python: For running the models and fine-tuning.
-    Transformers: Utilized for working with pre-trained models and fine-tuning.
-    GPT-2: For initial fine-tuning attempts.
-    GPT-4 (gpt-4o): For more advanced inference and improved accuracy.

## The Results of **gpt4o-mini** model
-     The prompt
  
  ![gpt_prompt](https://github.com/user-attachments/assets/e8167bc2-7926-4e65-bac0-8be6c6c6697d)


-     The Result
  ![gpt4o](https://github.com/user-attachments/assets/ae90edf4-4f95-4265-979e-3b12c37b50c6)
